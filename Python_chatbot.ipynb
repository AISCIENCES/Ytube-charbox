{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':\"File ID here\"})   # replace the id with id of file you want to access\n"
      ],
      "metadata": {
        "id": "Aq8ZCOA7gDBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d789d4ae-ce64-4b1a-8b24-630b73562d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFTdWXBNKhY"
      },
      "source": [
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddQDX1wQKYMQ"
      },
      "source": [
        "\n",
        "def bag_of_words(tokenized_sentence, words):\n",
        "    \"\"\"\n",
        "    return bag of words array:\n",
        "    1 for each known word that exists in the sentence, 0 otherwise\n",
        "    example:\n",
        "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
        "    \"\"\"\n",
        "    # stem each word\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
        "    # initialize bag with 0 for each word\n",
        "    bag = np.zeros(len(words), dtype=np.float32)\n",
        "    for idx, w in enumerate(words):\n",
        "        if w in sentence_words: \n",
        "            bag[idx] = 1\n",
        "\n",
        "    return bag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('intents.json', 'r') as f:\n",
        "    intents = json.load(f)"
      ],
      "metadata": {
        "id": "nmRmUz8cft2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words=[]\n",
        "tags=[]\n",
        "xy=[]\n",
        "for intent in intents[\"intents\"]:\n",
        "  tag=intent['tag']\n",
        "  tags.append(tag)\n",
        "\n",
        "  for pattern in intent['patterns']:\n",
        "    w=tokenize(pattern)\n",
        "    all_words.extend(w)\n",
        "    xy.append((w,tag))\n"
      ],
      "metadata": {
        "id": "ExR7oOTaxP4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_words=['?','.','!']\n",
        "all_words=[stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words=sorted(set(all_words))\n",
        "tags=sorted(set(tags))\n",
        "\n",
        "print(len(all_words), 'unique stmmed words')\n"
      ],
      "metadata": {
        "id": "Nb-ehOyNxP1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8842ec-14f1-4714-d17e-b0c65ff8f87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 unique stmmed words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=[]\n",
        "y_train=[]\n",
        "\n",
        "for (pattern_sentence,tag) in  xy:\n",
        "  bag=bag_of_words(pattern_sentence,all_words)\n",
        "  X_train.append(bag)\n",
        "  label=tags.index(tag)\n",
        "  y_train.append(label)\n",
        "\n",
        "X_train=np.array(X_train)\n",
        "y_train=np.array(y_train)"
      ],
      "metadata": {
        "id": "rXsizdyyxPzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV2Xx8dM2H_t"
      },
      "source": [
        "\n",
        "## Creating our Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzu2XD-5QhK1"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btm83RGv2Z2s"
      },
      "source": [
        "class ChatDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_train)\n",
        "        self.x_data = X_train\n",
        "        self.y_data = y_train\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=1000\n",
        "batch_size=8\n",
        "learning_rate=0.001\n",
        "input_size=len(X_train[0])\n",
        "hidden_size=8\n",
        "output_size=len(tags)\n",
        "print(input_size, output_size)"
      ],
      "metadata": {
        "id": "hvx0ZIXczbyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32742342-eac1-4bb4-985b-a9896e816c27"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=ChatDataset()\n",
        "train_loader=DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True,num_workers=0)\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model=NeuralNet(input_size,hidden_size,output_size).to(device)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer= torch.optim.Adam(model.parameters(),lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "xxTvxaVMzbwF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "        words = words.to(device)\n",
        "        labels = labels.to(dtype=torch.long).to(device)\n",
        "        # Forward pass\n",
        "        outputs = model(words)\n",
        "        # if y would be one-hot, we must apply\n",
        "        # labels = torch.max(labels, 1)[1]\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "print(f'final loss: {loss.item():.4f}')\n",
        "data = {\n",
        "\"model_state\": model.state_dict(),\n",
        "\"input_size\": input_size,\n",
        "\"hidden_size\": hidden_size,\n",
        "\"output_size\": output_size,\n",
        "\"all_words\": all_words,\n",
        "\"tags\": tags\n",
        "}"
      ],
      "metadata": {
        "id": "y0-HrT5tzboL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93f506e-dffe-48a2-cde2-507a79422a9e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 1.1547\n",
            "Epoch [200/1000], Loss: 0.0885\n",
            "Epoch [300/1000], Loss: 0.0859\n",
            "Epoch [400/1000], Loss: 0.0061\n",
            "Epoch [500/1000], Loss: 0.0036\n",
            "Epoch [600/1000], Loss: 0.0034\n",
            "Epoch [700/1000], Loss: 0.0009\n",
            "Epoch [800/1000], Loss: 0.0041\n",
            "Epoch [900/1000], Loss: 0.0008\n",
            "Epoch [1000/1000], Loss: 0.0006\n",
            "final loss: 0.0006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "File=\"data.pth\"\n",
        "torch.save(data,File)\n",
        "\n",
        "print(\"saved\")"
      ],
      "metadata": {
        "id": "WEh_7pnhzo3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55cf058-ba7e-485d-db00-199aeabdcd45"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NDnYNCDlzoz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ErP6HoOSzow7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MUnbnI4nzoa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH52MJobTFEU"
      },
      "source": [
        "\n",
        "## Loading our Saved Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX0f_8TgPRqK",
        "outputId": "fe8b1f9b-daf7-41ed-a686-11770eaa8b37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with open('intents.json', 'r') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLOf1gRd2-YH"
      },
      "source": [
        "\n",
        " \n",
        "## Using the Chatbot:\n",
        "---\n",
        "Our Model is Ready. Now we will finally chat with our chat-bot. As our training data was very limited, we can only chat about a handful of topics. You can train it on a bigger dataset to increase the chatbot’s generalization / knowledge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_tGgw41THXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b47e6d-09f9-48d3-9d1c-d6a97723e20e"
      },
      "source": [
        "\n",
        "bot_name = \"Sam\"\n",
        "print(\"Let's chat! (type 'quit' to exit)\")\n",
        "while True:\n",
        "    # sentence = \"do you use credit cards?\"\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence == \"quit\":\n",
        "        break\n",
        "\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.75:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
        "    else:\n",
        "        print(f\"{bot_name}: I do not understand...\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'quit' to exit)\n",
            "You: hi\n",
            "Sam: Hello, thanks for visiting\n",
            "You: whats in the menu?\n",
            "Sam: I do not understand...\n",
            "You: what is in the menu?\n",
            "Sam: Hi there, what can I do for you?\n",
            "You: menu\n",
            "Sam: I do not understand...\n",
            "You: tell me joke\n",
            "Sam: Why did the hipster burn his mouth? He drank the coffee before it was cool.\n",
            "You: can i pay cash ?\n",
            "Sam: We accept most major credit cards, and Paypal\n",
            "You: hoe long does it take for the order\n",
            "Sam: I do not understand...\n",
            "You: how long order\n",
            "Sam: Delivery takes 2-4 days\n",
            "You: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-YmHiFdhjUc8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}